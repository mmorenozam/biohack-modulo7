---
logo: images/icon1_nb.png
lang: es
filters:
  - timer
format: 
  letterbox-revealjs:
    theme: custom.scss
    progress: false
    menu: true
    width: 1400
    height: 720
    slide-number: true
    preview-links: auto
    touch: true
    chalkboard:
      theme: whiteboard
      boardmarker-width: 4
      buttons: false
    revealjs-plugins:
      - pointer
      
callout-appearance: simple
---

## 

:::::: columns
::: {.column width="37.5%"}
![](images/icon1_nb.png){style="margin-left:-50px"}
:::

:::: {.column width="60%"}
::: {.title data-id="title"}
Módulo 7: Otros métodos estadísticos
:::

Mauricio Moreno, PhD
::::
::::::

![](images/nathana-reboucas-AGLTICzftCc-unsplash.jpg){.image-left}

# Antes de comenzar

## Mapas de calor con `{ggplot2}`!

::: incremental

-   Hace poco descubrí un nuevo paquete que nos ayuda a realizar mapas de calor con `{ggplot2}`

-   Su nombre es `{tidyheatmaps}` y puedes ver acerca del mismo [aquí](https://stemangiola.github.io/tidyHeatmap/){target="_blank"}

:::

. . .

::: columns
::: {.column width="50%"}

```{r echo=T, eval=F}
library(tidyheatmaps)
tidyheatmap(data_exprs,
            rows = external_gene_name,
            columns = sample,
            values = expression,
            scale = "row",
            cluster_rows = TRUE,
            cluster_cols = TRUE,
            display_numbers = TRUE
)
```

:::

::: {.column width="50%"}

```{r echo=F, eval=T}
library(tidyheatmaps)
tidyheatmap(data_exprs,
            rows = external_gene_name,
            columns = sample,
            values = expression,
            scale = "row",
            cluster_rows = TRUE,
            cluster_cols = TRUE,
            display_numbers = TRUE
)

```
:::
:::

## Heterocedasticidad en el ANOVA {.smaller}

::: incremental

-   Usaremos los datos de las ranas arbóreas de ojos rojos de Touchon (disponibles en formato csv en la pestaña de recursos del sition web del curso).

-   Estos corresponden a una investigación que llevo por objetivo el estudiar las interacciones entre predadores y recursos en el desarrollo de estas ranas desde su eclosión hasta el término de la metamorfosis.

-   Nos enfocaremos en las variables:

    -   Respuesta: Edad de metamorfosis (`Age.DPO`)
    
    -   Independientes: 
    
        -   Predadores (`Pred`), 3 niveles: **L** = letales, **NL** = no letales y **C** = control 
        
        -   Recursos (`Res`), 2 niveles: **Lo** = bajos y **Hi** = altos
        
-   El diseño experimental cae en la categoría de un DFC en bloques.

-   La pregunta de investigación en esta caso particular, es el determinar si la edad del término de la metaformosis se ve afectada por la presencia/ausencia de depredadores y abundancia/carencia de recursos.

:::

## Heterocedasticidad en el ANOVA {.smaller visibility="uncounted"}

-   Para ahorrarnos tiempo, supongamos que ya corrimos un primer ANOVA no aditivo de dos vías, y encontramos desviaciones de la normalidad que corregimos con la transformación del logaritmo de `Age.DPO`.

```{r echo=T, eval=T}
library(car)
ranas <- read.csv("datos/touchon.csv")
lm <- lm(log(Age.DPO) ~ Pred * Res, data = ranas)
residuos <- lm$residuals
shapiro.test(residuos)
leveneTest(lm)
```

. . .

-   Como podemos ver, la normalidad de los residuos ya no es un problema, pero la homogeinidad de varianzas si lo es.

## Corrección de Welch en ANOVA {.smaller}

::: incremental

-   En ANOVA, de manera similar a las pruebas t, es posible usar la corrección de Welch para cuando el supuesto de la heterodasticidad no se cumple.



-   La desventaja radica en que este test solo es aplicable en la estructura del ANOVA de una vía

-   Esto no es un problema si sabemos re-parametrizar el ANOVA de dos vías original.


:::

. . .

::: columns
::: {.column width="50%"}
- Colapsamos los factores un único factor

```{r echo=T, eval=T}
ranas$log.Age.DPO <- log(ranas$Age.DPO)
ranas$tratamiento <- paste(ranas$Pred, ranas$Res, sep = "-")
```




:::

::: {.column .fragment width="50%"}
-   La corrección de Welch para ANOVA está disponible en el paquete `{rstatix}`

```{r echo=T, eval=T}
library(rstatix)
anova_welch <- ranas |>
  welch_anova_test(log.Age.DPO ~ tratamiento)
anova_welch
```
:::
:::


## Corrección de Welch en ANOVA {.smaller}

-   Otra desventaja es el no contar más con las agrupaciones por letras de las comparaciones múltiples

::: columns
::: {.column width="40%"}

```{r echo=T, eval=F}
comparaciones <- ranas |>
  games_howell_test(log.Age.DPO ~ tratamiento)
comparaciones
```

:::

::: {.column .fragment width="60%"}

```{r echo=F, eval=T}
comparaciones <- ranas |>
  games_howell_test(log.Age.DPO ~ tratamiento)
comparaciones

```
:::
:::

## Corrección de Welch en ANOVA {.smaller}

-   Pero podemos llevar a cabo gráficos de comparaciones por pares con la ayuda de `{ggpubr}`

::: columns
::: {.column width="50%"}

```{r echo=T, eval=F}
library(ggpubr)
library(ggplot2)
ggboxplot(ranas, 
          x = "tratamiento", 
          y = "log.Age.DPO") +
  stat_pvalue_manual(comparaciones, 
                     label = "p.adj", 
                     y.position = seq(5.1, 6, 
                                      length.out = 5), 
                     hide.ns = T)
```

:::

::: {.column .fragment width="50%"}

```{r echo=F, eval=T}
library(ggpubr)
library(ggplot2)
ggboxplot(ranas, 
          x = "tratamiento", 
          y = "log.Age.DPO") +
  stat_pvalue_manual(comparaciones, 
                     label = "p.adj", 
                     y.position = seq(5.1, 6, length.out = 5), 
                     hide.ns = T)
```
:::
:::

# Regresión lineal

## Generalidades {.smaller}

::: incremental

-   Se diferencia del ANOVA al considerar uno o más predictores continuos (no factores categóricos).

-   Los supuestos de la regresión lineal son:

    -   Existencia de una relación lineal entre las variables continuas objeto de la regresión
    
    -   Normalidad de los residuos
    
    -   Que no exista multicolinearidad (en el caso de regresión múltiple)
    
    -   Que no exista auto correlación (que las observaciones no dependan una de otra dentro de una misma variable)
    
    -   Homogeneidad de la varianza de los residuos

-   Contrario al ANOVA, no existen correcciones o métodos alternativos cuando las transformaciones fallan.

-   Por esto, lo que se recomienda hacer es mencionar todos los detalles de la conducción del modelo. 

-   En regresión lineal es quizá en el método que más se abusa del remover outliers. 

:::

## Regresión lineal simple en R {.smaller}

::: incremental

-   Usando los datos de Touchon, podríamos preguntarnos si el tamaño de las ranas al final de la metamorfosis `SVL.final` está influenciado por la edad en finalizar la metamorfosis `Age.DPO`.

-   Esta regresión lineal sería de la siguiente forma:

:::

. . .

```{r echo=T, eval=T, error=T}
reg1 <- lm(SVL.final ~ Age.DPO, data = ranas)
summary(reg1)
```

. . . 

- Pero antes de cualquier inferencia, vamos a darle un vistazo a los diagnósticos de la regresión lineal

## Diagnósticos de la regresión lineal

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=5}
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```


## Diagnósticos de la regresión lineal {visibility="uncounted"}

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.width=6}
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```

## Diagnósticos de la regresión lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(reg1, 1)
```
:::

::: {.column width="60%"}

**Residuos vs. Valores ajustados**

En el ANOVA vimos como este plot sugería departuras de la homocedasticidad. En el caso de la regresión lineal, los residuos al no estar agrupados en categorías presentan mayor información sobre este supuesto. Adicionalmente, curvaturas en la línea roja evidencian también departuras de la linearidad. Esto quiere decir que la relación entre las variables no es completamente lineal. A veces esto puede corregirse con transformaciones.

:::
:::

## Diagnósticos de la regresión lineal {visibility="uncounted" .smaller}

![](images/kutner.png){fig-align="center"}

(a) Es ideal. (b) Es indicativo de no linearidad. (c) Evidencia de heterocedasticidad. (d) Evidencia de una tendencia temporal



## Diagnósticos de la regresión lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(reg1, 5)
```
:::

::: {.column width="60%"}
**Residuos vs. Apalancamiento**

Aquellos puntos que estén etiquetados con números son mostrados como posibles outliers bajo dos criterios:

-   Están por fuera de los límites de la regla del rango intercuartílico (IQR), y

-   Marcados como outliers con influencia de apalancamiento mediante la prueba de Cook (distancia de Cook).

El segundo criterio es un argumento sólido para remover outliers.

:::
:::

## Pruebas formales de los supuestos {.smaller}

::: incremental

-   Como vimos, los supuestos de la regresión lineal son más que para el ANOVA.

-   Existen varias pruebas formales para chequear cada uno de sus supuestos, sin embargo rara vez son empleadas.

-   La razón yace en que si los aplicáramos todo el tiempo, no haríamos regresiones lineales ni el 10\% de las veces.

-   Si tienes curiosidad en estas pruebas puedes visitar [este enlace.](https://rpubs.com/aryn999/LinearRegressionAssumptionsAndDiagnosticsInR){target="_blank"}

-   De alguna manera podemos decir que de hecho, los estadísticos somos más laxos con la regresión lineal siempre y cuando estas departuras de los supuestos fueran debidamente documentadas y plasmadas en los trabajos científicos, lo cual lamentablemente no pasa muy a menudo.

-   Existen por supuesto métodos que no dependen de todos estos supuestos (por ejemplo: regresiones lineales Bayesianas, modelos lineales generalizados correctamente parametrizados) pero no son parte de este curso.

:::

## Transformación de datos {.smaller}


::: {.columns .v-center-container}
::: {.column width="50%"}
```{r echo=T, eval=F, error=T, fig.height=6, fig.width=6}
reg1 <- lm(SVL.final ~ Age.DPO, data = ranas)
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```

```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
reg1 <- lm(SVL.final ~ Age.DPO, data = ranas)
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```
:::

::: {.column width="50%"}
```{r echo=T, eval=F, error=T, fig.height=6, fig.width=6}
reg1 <- lm(log(SVL.final) ~ log(Age.DPO), data = ranas)
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```

```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
reg1 <- lm(log(SVL.final) ~ log(Age.DPO), data = ranas)
par(mfrow = c(2, 2))
plot(reg1)
par(mfrow = c(1, 1))
```
:::
:::


## Interpretación de la regresión lineal {.smaller .scrollable}

$$
y = mx + b
$$

::: {.columns .v-center-container}
::: {.column width="50%"}

```{r echo=F, eval=T, error=T}
summary(reg1)
```

-   Por cada incremento en una unidad del logaritmo de `Age.DPO`, tenemos 0.12 unidades en descenso del logaritmo de `SVL.final`
:::

::: {.column width="50%"}
```{r echo=T, eval=T, error=T}
ggplot(ranas, aes(x = log(Age.DPO), y = log(SVL.final))) +
  geom_point()+
  geom_smooth(method = "lm")
```
:::
:::



## Interpretación de la regresión lineal {.smaller  visibility="uncounted"}

::: incremental

-   Sin embargo una interpretación en la escala logarítmica no es completamente entendible, al menos para alguien ajeno al análisis que realizamos.

-   Podríamos hacer la retransformación de las variables a sus unidades originales y generar un gráfico de las predicciones. A la final se reduce a matemática básica.

-   Afortunadamente la librería `{ggeffects}` nos puede ayudar

:::

. . . 

::: {.columns .v-center-container}
::: {.column width="50%"}

```{r echo=T, eval=T, error=T}
library(ggeffects)
predicciones <- ggpredict(reg1)
predicciones
```


:::

::: {.column width="50%"}

```{r echo=T, eval=T, error=T, fig.align='center', fig.height=4, fig.width=5}
plot(predicciones$Age.DPO)
```
:::
:::

## Regresión lineal múltiple en R {.smaller}

::: incremental

-   Es usada para predecir una sola variable continua (y) en función de múltiples predictores continuos (un set de variables X).

-   Tiene prácticamente los mismos supuestos que la regresión lineal simple:

    -   Linearidad de los predictores
    
    -   Homogeneidad de la varianza (homocedasticidad)
    
    -   Independencia de los errores (residuos)
    
    -   Normalidad de los residuos
    
    -   Independencia de los predictores

-   Un ejemplo de una regresión múltiple podría expresarse mediante la siguiente ecuación

:::

. . . 

```{=tex}
\begin{align}
y &= \beta_0 + \beta_1\,X_1 + \beta_2\,X_2 \dots \beta_n\,X_n
\end{align}
```

## Pasos para una regresión múltiple {.smaller}

::: incremental

-   El llegar a un modelo apropiado se convierte en lo que algunos estadísticos llaman el "arte de modelar":

    1.    Empezar por lo que se le conoce como un modelo completo (incluyendo todas las variables continuas disponibles).
    
    2.    Realizar una selección automática de variables sobre el modelo del paso 1.
    
    3.    Checar manualmente por colinearidad entre las variables del modelo resultante del paso 2.
    
    4.    Revisar si las variables incluidas tienen sentido (biológico),
    
    5.    Checar los supuestos de normalidad y homocedasticidad.
    
    6.    Realizar transformaciones de ser necesario.
    
    7.    Interpretar resultados.
    
-   Estos pasos son solo mi recomendación. Dependiendo del problema, quizá ni siquiera sirvan y sus análisis estarán de la mano de más de su buen entendimiento de los datos y los fenómenos que deseen explicar.

:::

## Datos que usaremos {.smaller}

::: incremental

-   Usaremos los datos de rotavirus en Berlin del archivo de Excel "rotXLS.xlsx" que contiene información sobre el conteo de casos de rotavirus en Berlín desde el año 2001 hasta el 2020.

-   Supongámos que queremos modelar la variable `cases` en función de todas las variables metereológicas a nuestra disposición. Para esto, aquí la descripción de esta tabla de datos

:::

::: columns
::: {.column width="50%" .fragment}
-   `date`: fecha de cierre de la toma de datos

-   `cases`: número de casos de rotavirus en la semana

-   `week`: semana epidemiológica

-   `incidence`: número de casos/100000 habitantes

-   `FM`: media diaria de velocidad del viento (m/s)

-   `RSK`: media diaria de lluvia (mm)
:::

::: {.column width="50%" .fragment}
-   `SHK_TAG`: media diaria de nieve (cm)

-   `PM`: media diaria de presión atmosférica (hPa)

-   `TMK`: media diaria de temperatura (°C)

-   `TXK`: media diaria de temperatura máxima (°C)

-   `TNK`: media diaria de temperatura mínima (°C)

-   `UPM`: media diaria de humedad relativa (%)
:::
:::

. . .

-   Sin embargo, antes de continuar, debemos hacer un preprocesamiento de datos ya que en la estructura original de estos se considera un efecto temporal dado por los años. Para simplificarlo, agruparemos los datos por meses y semanas epidemiológicas.


## Preprocesamiento de datos {visibility="uncounted" .smaller}

-   Asegúrate de tener instaladas las librerías `{dplyr}` y `{lubridate}` antes de correr este código

```{r echo=T, eval=T, error=T}
library(dplyr)
library(readxl)
library(lubridate)
rot_berlin <- read_excel("datos/rotXLS.xlsx")
rot_berlin$month <- month(rot_berlin$date)
rot_berlin <- rot_berlin %>%
  group_by(month, week) %>%
  summarise(incidence = mean(incidence),
            cases = round(mean(cases),0),
            FM = mean(FM),
            RSK = mean(RSK),
            SHK_TAG = mean(SHK_TAG),
            PM = mean(PM),
            TMK = mean(TMK),
            TXK = mean(TXK),
            TNK = mean(TNK),
            UPM = mean(UPM))
rot_berlin$month <- as.factor(rot_berlin$month)
rot_berlin$week <- as.factor(rot_berlin$week)
```

## Modelo completo {.smaller}

-   Empezaremos formulando un modelo completo para estos datos de la siguiente manera:

```{r echo=T, eval=T, error=T}
lm1 <- lm(cases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM, data = rot_berlin)
```

::: incremental

-   En la función `lm` se pueden incluir términos de órdenes superiores (interacciones, cuadrados, cubos, etc) con variables continuas.

-   Por simplicidad, únicamente consideraremos predictores de primer orden.

-   Es importante tener en cuenta que así incluyésemos términos de órdenes superiores en `lm`, todavía sería considerado un modelo lineal ya que los coeficientes de estos términos seguirán siendo estimados de manera lineal (la variable de respuesta es una combinación lineal de los predictores que puede o no incluir transformaciones lineales de estos últimos).

-   Un ejemplo de una relación no lineal de los predictores se da cuando los coeficientes de la ecuación forman parte de expresiones no lineales:

:::

. . . 

$$
y = \beta_{1}e^{\beta_2X}
$$


## Selección de variables {.smaller}

::: incremental

-   La selección automática de variables funciona con un algoritmo relativamente sencillo:

    -   Retira una variable a la vez del modelo, calcula un criterio de comparación y repite el proceso
    
    -   Usa ese criterio de comparación con respecto a un modelo nulo (sin ningún predictor) y devuelve el modelo que haya obtenido la mejor valoración.
    
-   El criterio de evaluación más usado para comparar modelos es el denominado criterio de información de Akaike (AIC), y es un estimador del error de predicción. Mientras menos sea el valor de AIC, mejores las predicciones que un modelo teoricamente será capaz de realizar.

-   Realizamos la selección de variables antes de cualquier diagnóstico o transformación ya que a veces estas últimas "exageran" la importancia de las variables en el caso de hacer la selección después.

-   La manera más sencilla de hacer una selección de variables es usando la función base de R `step` 

:::

. . .

```{r echo=T, eval=F, error=T}
step(lm1)
```

## Selección de variables {.smaller visibility="uncounted"}

```{r echo=T, eval=T, error=T}
step(lm1)
```

## Multicolinearidad {.smaller}

-   De acuerdo a la selección automática, nuestro modelo sería hasta el momento:

```{r echo=T, eval=F, error=T}
cases ~ FM + PM + TMK + TXK + UPM
```

::: incremental

-   Ningún método de selección de variables automático es perfecto. 

-   En este caso, aunque obvio, sabemos que las variables `TMK` y `TXK` deben estar correlacionadas al ser medidas de temperatura correspondientes al mismo día.

-   Bien podríamos deshechar una de las dos, pero cuando no sabemos la naturaleza de las variables, es mejor llevar a cabo un análisis de correlación antes de checar el modelo por sus supuestos.

-   Cuando exploramos datos (módulo 4) ya hicimos una primera aproximación con las matrices de dispersión (paquete `{GGally}`. Sin embargo, en ellas solo vimos el coeficiente de correlación junto al código de significancia.

-   Para estar seguros de que eliminaremos variables correctamente, es mejor dar un vistazo a las matrices de correlación directamente.

:::

## Matrices de correlación {.scrollable .smaller}


-   Para calcular la matriz de correlación de un conjunto de datos usaremos la librería `{Hmisc}`


```{r echo=T, eval=T, error=T}
library(Hmisc)
matriz <- rcorr(as.matrix(rot_berlin[,c(5, 8, 9, 10, 12)]))
matriz
```

. . .

-   En este paso, recomiendo el mirar por fuera de la diagonal y eliminar del análisis una variable de cualquier par que tenga un coeficiente de correlación exactamente igual a 1. En este caso, eliminaré `TMK`

## ¿Tiene todo esto sentido? {.smaller}

-   Hasta aquí, nuestro modelo candidato sería el siguiente


```{r echo=T, eval=F, error=T}
cases ~ FM + PM + TXK + UPM
```

::: incremental

-   Los algoritmos usados aplican criterios estadísticos que no necesariamente denotan características biológicas.

-   Considerando que el rotavirus se contagia principalmente por contacto directo o indirecto con heces fecales de alguien infectado y no se ha reportado ningún caso de transmisión por aire contaminado, ¿tiene sentido mantener las variables `FM` (velocidad media diaria del viento) y `PM` (presión atmosférica media diaria) como parte del modelo?

-   Personalmente, pienso que no. Para mí, el modelo candidato sería el siguiente

:::

. . .

```{r echo=T, eval=F, error=T}
lm2 <- lm(cases ~ TXK + UPM, data = rot_berlin)
```

## Diagnósticos de la regresión múltiple {.smaller}

::: incremental

-   Una vez que tengo definido mi modelo candidato lo pondré a prueba de los supuestos:

:::

. . .

```{r echo=T, eval=T, error=T}
lm2 <- lm(cases ~ TXK + UPM, data = rot_berlin)
```

::: incremental

-   Vamos a introducir otra librería muy útil cuando nos encontramos ante modelos de múltiples variables: `{performance}`.

-   `{performance}` nos ofrece la posibilidad de chequear dos diagnósticos adicionales:

    -   La predicción del modelo (basándose en una aproximación Bayesiana)
    
    -   La colinearidad
    
-   También se lo puede utilizar para modelos univariables (como la regresión lineal).

:::

. . .

```{r echo=T, eval=F, error=T}
library(performance)
check_model(lm2)
```

## Diagnósticos de la regresión múltiple {.smaller visibility="uncounted"}

```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
library(performance)
check_model(lm2)
```

## Diagnósticos de la regresión múltiple {.smaller visibility="uncounted"}

::: {.columns .v-center-container}
::: {.column  width="40%"}
![](images/Rplot.png){fig-align="center"}
:::

::: {.column  width="60%"}
**Chequeo de la predicción posterior**

Este gráfico contrapone la densidad de la distribución de la variable de respuesta con las densidades de las predicciones obtenidas del modelo mediante un proceso de sampleo Bayesiano (por eso apreciamos varias líneas azules). Nos da una idea de qué tan adecuado es nuestro modelo para predecir los valores observados. Idealmente estas dos deberían superponerse.

:::
:::

## Diagnósticos de la regresión múltiple {.smaller visibility="uncounted"}

::: {.columns .v-center-container}
::: {.column width="40%"}
```{r echo=F, eval=T, error=T, message = F, warning=F, fig.height=4.5, fig.width=6}
coli <- check_collinearity(lm2)
plot(coli)
```
:::

::: {.column width="60%"}
**Chequeo de la colinearidad**

Aquí vemos distribuidas en el eje X cada una de las variables que estamos usando como predictores mientras que en el eje Y tenemos el factor de inflación de la varianza (VIF) que cada una de estas contribuye al modelo. Nos da una idea de que variables podríamos eliminar basados en mantener únicamente variables independientes entre sí como predictores.

:::
:::

## Transformaciones {.smaller}

::: incremental

-   Del gráfico de la predicción posterior evidenciamos que los datos observados de incidencia de rotavirus son asimétricos hacia la izquierda (o asimetría positiva).

-   Usualmente la transformación que mejor funciona en este caso es el logaritmo natural.

:::

. . . 

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "1|2"
lm3 <- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin)
check_model(lm3)
```


```{r echo=F, eval=T, error=T}
lm3 <- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin )
``` 

## Transformaciones {.smaller visibility="uncounted" .scrollable}

```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
library(performance)
check_model(lm3)
```

## Removiendo outliers {.smaller}

::: incremental

-   La distancia de Cook nos ha ayudado a identificar una observación claramente influyente.

-   Para continuar, removeremos esa observación para ver que tanto ayuda a nuestro análisis.

:::

. . . 

```{r echo=T, eval=F, error=T, fig.align='center', fig.width=8, fig.height=10}
rot_berlin_out <- rot_berlin[-22, ]
lm4 <- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin_out)
check_model(lm4)
```

## Removiendo outliers {.smaller}


```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
rot_berlin_out  <-  rot_berlin[-22, ]
lm4 <- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin_out)
check_model(lm4)
```


## Modelo final {.smaller .scrollable}

::: incremental

-   Una vez que hemos llegado a nuestro modelo, revisamos los resultados (este paso lo pudimos hacer en cada paso)

:::

. . . 

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
summary(lm4)
```



## Interpretación {.smaller}

::: columns
::: {.column width="50%"}
```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
summary(lm4)
```
:::

::: {.column width="50%"}
-   Por cada incremento de una unidad de `TXK`, el número de casos decrece 0.16 unidades, teniendo el resto de variables constantes.

-   Por cada incremente de una unidad de `UPM`, el número de casos decrece 0.13 unidades, teniendo el resto de variables constantes.

-   Pero ten presente que este resultado está en escala logarítmica

:::
:::

## Interpretación {.smaller visibility="uncounted"}

-   Haremos uso nuevamente de la librería `{ggeffects}` para lidiar con la retransformación y `{ggplot2}` junto a `{patchwork}` para graficar las predicciones.

::: columns
::: {.column width="50%"}
```{r echo=T, eval=T, error=T}
library(ggeffects)
library(ggplot2)
library(patchwork)
predicciones <- ggpredict(lm4)
predicciones[[1]]
```
:::

::: {.column width="50%"}

```{r echo=T, eval=T, error=T}
predicciones[[2]]
```

:::
:::

## Interpretación {.smaller visibility="uncounted"}

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=4}
p1 <- predicciones[[1]]
p2 <- predicciones[[2]]
plot(p1) + plot(p2)
```

<!-- ## Ejercicio 5.1 {.smaller} -->

<!-- -   Realiza un modelo de regresión lineal múltiple para los mismos datos que acabas de ver siguiendo tu propia iniciativa: -->

<!--     -   Puedes cambiar el orden de los pasos que sugerí -->

<!--     -   Realizar chequeos de la significancia de los coeficientes de los modelos candidatos entre paso y paso (cosa que yo no hice) -->

<!--     -   Puedes llevar a cabo una selección de variables manual, o cambiar el argumento `direction` de la función `step` por "forward" o "backward" -->
    
# Antes de continuar

## El mágico $R^2$

![](images/vieja.jpg){fig-align="center"}

## El mágico $R^2$ {visibility="uncounted" .smaller}

::: incremental

-   Quizá muchos hayan escuchado que un $R^2$ cercano a 1 es "ideal" cuando realizamos una regresión lineal.

-   Recuerdo incluso haber sido indoctrinado acerca de márgenes para un buen $R^2$ (algo así como que por encima del 80\% es "bueno", mayor al 90\% es excelente y 100\% es el Nirvana).

-   En breve, $R^2$ **NO ES NINGUNA DE LAS SIGUIENTES COSAS**:

    -   Una métrica de bondad de ajuste[: no nos dice si el modelo se ajusta bien a los datos.]{.fragment}
    
    -   Una métrica del error de predicción[: no mide para nada que tan bueno es el modelo para predecir futuras observaciones.]{.fragment}
    
    -   Una métrica que permita comparar modelos usando variables transformadas[: es común jugar a transformar los datos para ver de que manera se puede inflarlo hacia el santo grial.]{.fragment}
    
    -   Una métrica que permita que tan bien una variable explica otra[: en el ejemplo que vimos, y en toda regresión lineal, si cambiamos el predictor por respuesta y viceversa, tendremos exactamente el mismo $R^2$]{.fragment}
    
-   $R^2$ es simplemente una medida de la cantidad de variación que un modelo específico explica. [¿Tiene alguna utilidad práctica?]{.fragment} [ no lo sé, en 10 años como estadístico no lo he usado nunca, al menos no, voluntariamente...]{.fragment}

:::

## El mágico $R^2$ {visibility="uncounted" .smaller}

. . .

-   Lo que visto es carnicerías de datos por inflar $R^2$ debido a esta mala interpretación que no se sabe su origen exacto ([pero quizá aquí uno de tantos culpables perdidos en la historia](https://psycnet.apa.org/record/1946-01733-001){target="_blank"}).

. . .

-   Acá les dejo unos cuantos recursos que pueden revisar en más detalle si les interesa:

    -   [El paper "How not to lie with Statistics: Avoiding common mistakes in Quantitative Political Science"](https://www.jstor.org/stable/2111095?casa_token=F0Om3ZPkjE4AAAAA%3AvR0lcSXuNHICl21EYDAoXSerVhME0AO_ZvkzayO1vYT6R3cCM9Ooy6-P9Wa6AEZN1Gcm960rjGFM9JVA4AJc4lm-nswzYJxdtiKr03H4tbVMRW16e35TlA){target="_blank"} Un artículo extenso pero que contiene una sección dedicada a desmitificar esta mala práctica.
    
    -   [Las notas de la clase del Prof. Cosma Shalizi de la Universidad Carnegie Mellon](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/10/lecture-10.pdf){target="_blank"} donde hermosamente destruye los mitos en torno al $R^2$ citando fórmulas y principios estadísticos.
    
    -   [Un blog de Clay Ford, consultor estadístico de la Universidad de Virginia](https://data.library.virginia.edu/is-r-squared-useless/){target="_blank"} donde demuestra con R que valores de $R^2$ cercanos a 0 no necesariamente implican un mal modelo, ni valores cercanos 1 son indicativo de modelos destacados. 

## El mágico $R^2$ en nuestro ejemplo {visibility="uncounted" .smaller}

::: incremental

-   Mediante la función `compare_performance` de la librería `{performance}`, se puede obtener un gráfico de telarañas que permite ver como el $R^2$ no sirve de nada ante modelos mejor formulados.

-   Ahora recordemos que al final eliminamos un outlier con el modelo que mejores diagnósticos terminamos. Para poner a todos los modelos candidatos en igualdad de condiciones, los corremos de nuevo sin ese outlier (además de utilizar una variable previamente transformada para los modelos 3 y 4, ya que `{performance}` no es capaz de retransformar por si solo)


:::

. . .

```{r echo=T, eval=F, error=T, fig.align='center', fig.width=5, fig.height=5}
rot_berlin$cases_comp <- rot_berlin$cases + 1
rot_berlin_out$cases_comp <- rot_berlin_out$cases + 1
lm1.1 <- lm(cases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM, data = rot_berlin_out)
lm2.1 <- lm(cases ~ TXK + UPM, data = rot_berlin_out)
lm3.1 <- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)
lm4.1 <- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)

compare_performance(lm1.1, lm2.1, lm3.1, lm4.1, rank = T)
```

## El mágico $R^2$ en nuestro ejemplo {visibility="uncounted" .smaller}

::: columns
::: {.column width="70%"}
```{r echo=T, eval=T, error=T, fig.align='center', fig.width=5, fig.height=5}
rot_berlin$cases_comp <- rot_berlin$cases + 1
rot_berlin_out$cases_comp <- rot_berlin_out$cases + 1
lm1.1 <- lm(cases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM, data = rot_berlin_out)
lm2.1 <- lm(cases ~ TXK + UPM, data = rot_berlin_out)
lm3.1 <- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)
lm4.1 <- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)

compare_performance(lm1.1, lm2.1, lm3.1, lm4.1, rank = T)
```
:::

::: {.column .fragment width="30%"}
```{r echo=T, eval=T, error=T, fig.align='center', fig.width=5, fig.height=5}
plot(compare_performance(lm1.1, lm2.1, lm3.1, lm4.1))
```
:::
:::




## El mágico $R^2$ en nuestro ejemplo {.smaller .scrollable visibility="uncounted"}

::: columns
::: {.column width="50%"}

-   El mejor modelo de acuerdo al mágico $R^2$

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
check_model(lm1.1)
```
:::

::: {.column .fragment width="50%"}

-   Nuestro pobre pero honrado mejor modelo

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
check_model(lm4.1)
```
:::
:::



# Introducción a modelos lineales generalizados

## ¿Qué son los modelos lineales generalizados? {.smaller}

::: incremental

-   En breve, los modelos lineales generalizados son aquellos que no consideran normalmente distribuida a la variable de interés.

-   Toman este nombre ya que generalizan la regresión lineal al permitirle relacionarse con la variable de respuesta a través de una función de enlace que transforma a esta última a la escala normal.

-   Por tanto, estos modelos también compartirán los supuestos de la homogeneidad de la varianza y normalidad de los residuos. Aunque dependiendo de cada función de enlace a usarse, habrán otros estadísticos de interés.

-   En vista de lo basta que es la metodología dentro de este apartado de la estadística, nos enfocaremos en tan solo dos ejemplos:

    -   La regresión de Poisson
    
    -   La regresión binomial negativa

:::


## Regresión de Poisson en R

::: incremental

-   En breve, la regresión de Poisson se usa para el modelado de datos discretos que representan el conteo de algún evento.

-   En el ejemplo que consideramos anteriormente, el número de casos de rotavirus es un ejemplo de este tipo de eventos.

-   La razón por la que ese modelo funcionó relativamente bien es porque inadvertidamente impusimos la función de enlace sobre los datos al aplicar la transformación logarítmica.

-   Veamos que sucede al implementarla en R

:::

. . .

```{r echo=T, eval=F, error=T, fig.align='center', fig.width=8, fig.height=10}
glm1 <- glm(cases ~ TXK + UPM, data = rot_berlin_out, family = "poisson")
check_model(glm1)
```

## Regresión de Poisson en R

```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
glm1 <- glm(cases ~ TXK + UPM, data = rot_berlin_out, family = "poisson")
check_model(glm1)
```

## Regresión binomial negativa {.smaller}

::: incremental

-   Vemos que el modelo usando la regresión de Poisson no mejora mucho en términos de los supuestos.

-   Como mencionamos, el gráfico de sobredispersión ya nos da un indicativo de que el modelo es incorrecto.

-   Una alternativa para lidiar con sobredispersión es usar la regresión binomial negativa

-   Para ello, usaremos la librería `MASS` que ofrece esta funcionalidad

:::

. . . 

```{r echo=T, eval=F, error=T, fig.align='center', fig.width=8, fig.height=10}
library(MASS)
glm2 <- glm.nb(cases ~ TXK + UPM, data = rot_berlin_out)
check_model(glm2)
```

## Regresión binomial negativa {.smaller}

```{r echo=F, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
library(MASS)
glm2 <- glm.nb(cases ~ TXK + UPM, data = rot_berlin_out)
check_model(glm2)
```

## Comparación de modelos

::: incremental

-   Comparemos primero todos los modelos que hemos llevado a cabo hasta aquí sin rankearlos

:::

. . .

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
library(flextable)
colformat_double(flextable(compare_performance(lm1.1, lm2.1, lm4.1, glm1, glm2)), digits = 3)
```

## Comparación de modelos {visibility="uncounted"}

::: incremental

-   Ahora rankeados

:::

. . .

```{r echo=T, eval=T, error=T, fig.align='center', fig.width=8, fig.height=10}
colformat_double(flextable(compare_performance(lm1.1, lm2.1, lm4.1, glm1, glm2, rank = T)), digits = 3)
```

## Consideraciones sobre la comparación de modelos {visibility="uncounted"}

::: incremental

-   La versatilidad de `{performance}` es que nos permite comparar entre modelos provenientes de distintas metodologías estadísticas (hace no más de 5 años eso no era posible).

-   Sin embargo, hay que tener en cuenta que para que las comparaciones sean válidas, los modelos tienen que haber sido ajustados sobre los mismos datos.

-   Por ejemplo, no hubiese sido correcto en este ejemplo comparar todos los modelos que llevamos a cabo sin que estos hubiesen sido ajustados sobre la tabla de datos sin el outlier.

:::

## {}

::: columns
::: {.column width="37.5%"}

:::
::: {.column width="60%"}

::: {.title data-id="title"}
[Ejercicios 7.1](https://mmorenozam.github.io/biohack-website/ejercicios_m7.html#ejercicios-7.1){target="_blank"}
:::

:::{.timer #Timer1 seconds=900 starton=interaction}
:::

:::
:::

![](images/catxie.png){.image-left}

# Análisis de Componentes Principales

## Introducción {.smaller}

::: incremental

-   Llamado también PCA (por sus siglas en Inglés), es un método **estadístico** multivariado que tiene por objetivo el reducir las dimensiones de un conjunto de datos.

-   Mediante esta reducción, se pueden simplificar y visualizar datos altamente complejos. Esto ayuda a la interpretación e identificación de procesos que de otra forma, no sería fácil el determinar.

-   Es por esta razón que el PCA (ó APC) es popular en biología al ser este un campo donde comúnmente se generan datos que pueden contener cientos de filas y columnas.

-   Las preguntas que se pueden contestar con APC incluyen:

    -   ¿Qué muestras son más o menos similares entre sí?
    
    -   ¿Qué variables independientes se comportan de manera similar?
    


:::

## Introducción {.smaller visibility="uncounted"}

-   El ACP encuentra la dirección de la máxima varianza en espacios multidimensionales a través de transformaciones lineales a un nuevo sistema coordenado.

. . .

![](images/pca1.png){fig-align="center"}

. . .

::: incremental

-   Este nuevo sistema coordenado está conformado por los llamados Componentes Principales (CP).

-   Existen tantos CP como variables (dimensiones) tengan nuestros datos.

-   Cada componente es un una combinación lineal de las variables originales y buscan explicar la mayor cantidad de varianza posible. Por ello, es práctica común reportar solo los dos primeros CP

:::


## Introducción {.smaller visibility="uncounted"}

![](images/pca1.png){fig-align="center"}

::: incremental

-   Las contribuciones de cada variable en el eje del CP están indicadas por una flecha (carga).

-   Estas cargas reflejan la correlación entre la variable y el CP. 

-   Mientras más larga es la carga, mayor la correlación. Indicando que la variable es más importante en explicar/controlar la diferencia entre las muestras a lo largo del CP.

-   En el gráfico, $CO_3$ y pH son por tanto las variables más importantes del CP1, y $Ca^{2+}$ y Salinity del CP2

:::

## Consideraciones antes de implementar APC {.smaller}


::: incremental

-   El input de un APC pueden ser dos o más variables continuas. El APC clásico no puede lidiar con variables categóricas.

-   Debido a las posibles diferencias en los órdenes de magnitud y varianzas entre las variables continuas objeto de estudio, es aconsejable el estandarizar los valores.

-   Estandarizar un valor es convertirlo a una distribución normal con media cero y desviación estándar 1. [R se encarga de este paso por nosotros.]{.fragment}

-   Los datos para un PCA no necesariamente tienen que cumplir los supuestos de normalidad y homogeneidad de las varianzas, así tampoco necesitan ser totalmente independientes.

-   Los principales resultados del APC son dos: **gráfico de puntuaciones** y el **gráfico de cargas**


:::


## ¿Qué NO hace el APC? {.smaller}

::: incremental

El APC no es un método estadístico dirigido a llevar pruebas de hipótesis o estadística inferencial. En más detalle:

1.    **No valores p o pruebas de hipótesis:** no provee valores p, intervalos de confianza o signficancia estadística como podemos esperar del ANOVA. Sirve para explicar varianza y encontrar patrones en los datos.

2.    **No es un modelo predictivo:** no intenta predecir una variable dependiente en función de un set de variables independientes.

3.    **No tiene definición entre variables dependientes y explanatorias:** trata a todas las variables de input por igual.

4.    **No provee interpretabilidad directa sobre las variables de input:** al convertir las variables originales a un nuevo eje coordenado de componentes principales, no ofrece interpretaciones cuantitativas de las variables que forman parte de las combinaciones lineales que dieron lugar a los componentes principales.

:::

## APC en R



##

::: columns
::: {.column width="60%"}
::: {.title data-id="title"}
Fin del módulo 7
:::

::: callout-tip
## Créditos de fotos

Foto portada por <a href="https://unsplash.com/@nathanareboucas?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Nathana Rebouças</a> en <a href="https://unsplash.com/photos/a-person-holding-a-calculator-in-their-hand-AGLTICzftCc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  
  

Foto final por <a href="https://unsplash.com/@furkanelveren?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Furkan Elveren</a> en <a href="https://unsplash.com/photos/a-hand-reaching-up-into-the-air-above-a-field-of-grass-20P5tXZFjEc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  

Resto de fotos: Varias fuentes
:::
:::

::: {.column width="37.5%"}
![](images/icon1_nb.png){style="margin-left:120px"}
:::
:::

![](images/furkan-elveren-20P5tXZFjEc-unsplash.jpg){.image-right}
